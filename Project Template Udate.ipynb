{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace806d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data  \n",
    "# The project should use a real-world dataset and include a reference to the source in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b417a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Importing\n",
    "# Import data from a flat file (.csv, .xls, xlsx, .txt, etc.)\n",
    "# Retrieve data using online SQL, APIs, or web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e3beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preparation\n",
    "# Create pandas DataFrame\n",
    "# Sorting, indexing, grouping\n",
    "# Drop duplicates, replace missing values\n",
    "# Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47572ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis\n",
    "# Conditional statements, looping, groupby\n",
    "# Define a custom function to create reusable code\n",
    "# Use NumPy functions\n",
    "# Dictionary or Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac899f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualisation\n",
    "# Generate at least two charts using Matplotlib or Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Insights\n",
    "# Derive five valuable insights from the analysis\n",
    "# Justify your insights with reference to the charts or analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Machine Learning\n",
    "# Describe what kind of prediction you could perform in future using machine learning and/or deep learning.\n",
    "# Would you use classification or regression methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7266f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Importing\n",
    "# Import data from a flat file (.csv, .xls, xlsx, .txt, etc.)\n",
    "# Retrieve data using online SQL, APIs, or web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d03f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Check will I need this\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "plt.style.use('ggplot') # Style for visualtisations\n",
    "# pd.set_option('max_colums', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ccc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data (and assign columns, header etc if necessary)\n",
    "# Create pandas DataFrame\n",
    "data = pd.read_csv('data.csv') # Yet to decide on dataset\n",
    "seconddata = pd.read_csv('seconddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data using online SQL, API or web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f26ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Dataset \n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape # This will tell us how many columns in the data set for pd.set_option('max_colums', 100) above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns # Will list the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes  # shows the type of object each column is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aadc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() # information on numeric data such as mean, median etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39dde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preparation\n",
    "# Create pandas DataFrame\n",
    "# Sorting, indexing, grouping\n",
    "# Drop duplicates, replace missing values\n",
    "# Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # run again to look at columns\n",
    "data.columns # this will show the list of columns and then we set up a subset for the columns we want to keep and analyse...\n",
    "                # simply copy and paste the list to here...\n",
    "data[[]]     # we can comment out the columns we don't want\n",
    "                     # the copy() \n",
    "\n",
    "        # Using the drop command to do the same...\n",
    "data.drop([], axis=1)  # list in the column names here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607271f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[]].copy() # creating our new dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60521b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3075bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing date from object to date time\n",
    "# data['date_64'] = pd.to_datetime(data['the_date_column_we_want_to_change'])\n",
    "\n",
    "# Rename columns\n",
    "# data = data.rename(columns={'old_name':'New Name', 'old_name_2': 'New Name 2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8137c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna() # are there any null values?\n",
    "data.isna().sum()  # helps us see where our missing values may be\n",
    "data.duplicated() # will show duplicated rows if there are any...does not show the original row...rather the duplicates.\n",
    "data.loc[data.duplicated()] # shows where they are.\n",
    "data.duplicated(subset=['New Name']) # find rows with the same value in 'New Name' column\n",
    "data.loc[data.duplicated(subset=['New Name'])]\n",
    "data.query('New Names == \"Bananas\"') # Shows dublicates of the Bananas row.\n",
    "\n",
    "########################## Time 19:17 #######################\n",
    "# ~ find the data.duplicated(subset=['New Name']) and put ~ symbol infront and make this the new dataset\n",
    "# data = data.loc[data.duplicated(subset=['New Name'])].reset_index(drop=True).copy()\n",
    "# reset index allows creates correct index for dataframe adn drop=True stops it from adding a new index column as is the standard for reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis\n",
    "# Conditional statements, looping, groupby\n",
    "# Define a custom function to create reusable code\n",
    "# Use NumPy functions\n",
    "# Dictionary or Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['New Name'].value_counts() # good to compare date to date / by month, day or year etc.\n",
    "ax = data['New Name'].value_counts().head(10).plot(kind='bar', title='Title')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('No. of trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data['Column_of_Interest'].plt(kind='hist', bins=20, title='Title')\n",
    "ax.set_xlabel('Yadda')\n",
    "ax.set_ylabel('Yadda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data['Column_of_Interest'].plt(kind='kde', bins=20, title='Title')\n",
    "ax.set_xlabel('Yadda')\n",
    "ax.set_ylabel('Yadda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELATIONSHIPS \n",
    "data.plot(kind='scatter', x='Column_of_Interest', y='Column_of_Interest_2', title='Title')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot( x='Column_of_Interest', y='Column_of_Interest_2', hue='Column_of_Interest_3', data=data)\n",
    "\n",
    "sns.pairplot(data, vars=['Col1', 'Col2', 'Col3'], hue='Col4') # will show how each of these columns interact with each other.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr = data[['Col1', 'Col2', 'Col3','Col4']].dropna().corr() # Shows correlation between values (numeric)\n",
    "\n",
    "sns.heatmap(data.corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f12fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking questions to answer.\n",
    "\n",
    "# What are the locations with the most uses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7969bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location Column'].value_counts()\n",
    "data.query('location')\\\n",
    "    .groupyby('Location')['Number of Bikes']\\\n",
    "    .agg(['mean', 'count']) \\\n",
    "    .query('count >= 1000') \\\n",
    "    .sort_values('mean')\\\n",
    "    .plot(kind='barh', figsize=(12, 5), title='Title, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6909d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the locations with the fewest uses?\n",
    "data['Location Column'].value_counts()\n",
    "data.query('location')\\\n",
    "    .groupyby('Location')['Number of Bikes']\\\n",
    "    .agg(['mean', 'count']) \\\n",
    "    .query('count <= 10') \\\n",
    "    .sort_values('mean')\\\n",
    "    .plot(kind='barh', figsize=(12, 5), title='Title, ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
